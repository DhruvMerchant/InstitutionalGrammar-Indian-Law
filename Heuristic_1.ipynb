{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g2UrNxQ1OYEG"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qk_wH8YEOakI"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "YivwpZmMEU7T",
    "outputId": "4613ed51-f030-430c-eeaf-f49474ae8bb5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-3861cf90-4691-4e1d-9deb-856caeee9e5c\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-3861cf90-4691-4e1d-9deb-856caeee9e5c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving heuristics.csv to heuristics.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znxPRdV0Egam",
    "outputId": "dea73470-f57e-4ef5-b527-8e3e0753d669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0\n",
      "0   Where immediately before the issue of a notifi...\n",
      "1   Where in respect of an industrial dispute rela...\n",
      "2   At the time of hearing, the authority may dire...\n",
      "3   The authority referred to in sub-section (6) m...\n",
      "4   Finality of orders constituting Board, Committ...\n",
      "5   Chief Inspector - The State Government may, by...\n",
      "6   Where the applicant succeeds in such proceedin...\n",
      "7   Penalty for obstructing Inspector. -Whoever wi...\n",
      "8   Protection to persons acting under the Act. - ...\n",
      "9   Transfer of cases from one Court to another. -...\n",
      "10  Removal of difficulties.-If any difficulty ari...\n",
      "11  Provided that the appropriate Government may, ...\n",
      "12  Provided that in relation to the State of Jamm...\n",
      "13  Provided further that when the provisions of t...\n",
      "14  Every employee shall be entitled to be paid by...\n",
      "15  Subject to the other provisions of this Act, e...\n",
      "16  Where in respect of any accounting year referr...\n",
      "17  In computing the allocable surplus under this ...\n",
      "18  Where the salary or wage of an employee exceed...\n",
      "19  Where an employee has not worked for all the w...\n",
      "20  Where for any accounting year, the allocable s...\n",
      "21  Where for any accounting year, there is no ava...\n",
      "22  The principle of set on and set off as illustr...\n",
      "23  Where in any accounting year any amount has be...\n",
      "24  Where an establishment newly set up, whether b...\n",
      "25  In the first five accounting year following th...\n",
      "26  From the eighth accounting year following the ...\n",
      "27  Where in any accounting year, an employee is f...\n",
      "28  If in any accounting year an establishment in ...\n",
      "29  Where any money is due to an employee by way o...\n",
      "30  Provided that every such application shall be ...\n",
      "31  Provided further that any such application may...\n",
      "32  Where any dispute arises between an employer a...\n",
      "33  Where, during the course of proceedings before...\n",
      "34  When an application is made to the said author...\n",
      "35  Where any dispute of the nature specified in s...\n",
      "36  Nothing contained in sub-section (1) shall ena...\n",
      "37  Where any dispute of the nature specified in s...\n",
      "38  When the said authority finds that the account...\n",
      "39  Where an employer fails to get the accounts au...\n",
      "40  The expenses of and incidental to, any audit u...\n",
      "41  Every employer shall prepare and maintain such...\n",
      "42  The appropriate Government may, by notificatio...\n",
      "43  Every Inspector shall be deemed to be a public...\n",
      "44  Any person required to produce any accounts, b...\n",
      "45  Nothing contained in this section shall enable...\n",
      "46  If the person committing an offence under this...\n",
      "47  Provided that nothing contained in this sub-se...\n",
      "48  Notwithstanding anything contained in sub-sect...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "df = pd.read_csv(io.BytesIO(uploaded['heuristics.csv']),header=None)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WjTbp0v9Fkco",
    "outputId": "0338e3ce-d6bd-4d92-bb07-d84893141fa7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-41c3caa1-cd22-4df0-a246-92df5e267ba2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where immediately before the issue of a notifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where in respect of an industrial dispute rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At the time of hearing, the authority may dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The authority referred to in sub-section (6) m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finality of orders constituting Board, Committ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41c3caa1-cd22-4df0-a246-92df5e267ba2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-41c3caa1-cd22-4df0-a246-92df5e267ba2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-41c3caa1-cd22-4df0-a246-92df5e267ba2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Where immediately before the issue of a notifi...\n",
       "1  Where in respect of an industrial dispute rela...\n",
       "2  At the time of hearing, the authority may dire...\n",
       "3  The authority referred to in sub-section (6) m...\n",
       "4  Finality of orders constituting Board, Committ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLC2L2wdE6r-",
    "outputId": "30a02c17-0d0e-43bc-894c-a3a61dbf3f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be \t 75 \t AUX \t ROOT \t [] \t ['were', ',', 'under', ',', 'then', ',', 'notwithstanding', ',', 'wages', 'shall', 'payable', 'deemed', '.']\n",
      "\n",
      "\n",
      "apply \t 133 \t VERB \t ROOT \t [] \t ['is', 'is', 'then', ',', 'notwithstanding', ',', 'rates', 'shall', 'not', 'to', 'during', 'and', 'made']\n",
      "\n",
      "\n",
      "direct \t 9 \t VERB \t ROOT \t [] \t ['At', ',', 'authority', 'may', 'employers', 'deposit', '.']\n",
      "paid \t 36 \t VERB \t ROOT \t [] \t ['amount', 'may', 'be', 'to']\n",
      "\n",
      "\n",
      "allow \t 41 \t VERB \t ROOT \t [] \t ['referred', 'may', ',', 'is', ',', 'preferred']\n",
      "\n",
      "\n",
      "Finality \t 0 \t NOUN \t ROOT \t [] \t ['of', '-', 'committee-']\n",
      "called \t 38 \t VERB \t ROOT \t [] \t ['order', 'shall', 'be', 'in', 'in', 'called']\n",
      "\n",
      "\n",
      "appoint \t 10 \t VERB \t ROOT \t [] \t ['Inspector', 'Government', 'may', ',', 'by', 'person', '.']\n",
      "\n",
      "\n",
      "calculate \t 14 \t VERB \t ROOT \t [] \t ['succeeds', ',', 'authority', 'shall', 'amount', 'but', 'for', ',', 'and', 'direct', '.']\n",
      "be \t 75 \t AUX \t ROOT \t [] \t ['shall', ',', 'without', ',', 'recoverable', '.']\n",
      "\n",
      "\n",
      "Penalty \t 0 \t NOUN \t ROOT \t [] \t ['for', '.']\n",
      "obstructs \t 7 \t VERB \t ROOT \t [] \t ['-Whoever', 'wilfully', 'Inspector', 'in', ',', 'or', 'fails', 'kept', 'punished', '.']\n",
      "\n",
      "\n",
      "Protection \t 0 \t NOUN \t ROOT \t [] \t ['to', '.', '-']\n",
      "lie \t 19 \t VERB \t ROOT \t [] \t ['suit', 'shall', 'against', 'for', '.']\n",
      "\n",
      "\n",
      "Transfer \t 0 \t NOUN \t ROOT \t [] \t ['of', 'to', '.']\n",
      "- \t 9 \t PUNCT \t ROOT \t [] \t []\n",
      "subordinate \t 16 \t ADJ \t ROOT \t [] \t ['Government', 'to', 'by', '.']\n",
      "\n",
      "\n",
      "do \t 24 \t VERB \t ROOT \t [] \t ['arises', ',', 'Government', 'may', ',', 'by', ',', 'anything', ',', 'inconsistent', '.']\n",
      "\n",
      "\n",
      "Provided \t 0 \t VERB \t ROOT \t [] \t ['apply']\n",
      "employing \t 95 \t VERB \t ROOT \t [] \t ['[', 'number', 'twenty', 'specified', ';', 'so', ',', 'however', ',', 'specified', '.']\n",
      "\n",
      "\n",
      "Provided \t 0 \t VERB \t ROOT \t [] \t ['construed']\n",
      "\n",
      "\n",
      "Provided \t 0 \t VERB \t ROOT \t [] \t ['further', 'construed', '.']\n",
      "\n",
      "\n",
      "entitled \t 4 \t VERB \t ROOT \t [] \t ['employee', 'shall', 'be', 'paid', ',', 'bonus', 'in', ',', 'provided']\n",
      "\n",
      "\n",
      "bound \t 13 \t VERB \t ROOT \t [] \t ['Subject', ',', 'employer', 'shall', 'be', 'pay']\n",
      "\n",
      "\n",
      "bound \t 42 \t VERB \t ROOT \t [] \t ['exceeds', ',', 'shall', ',', 'in', ',', 'be', 'pay', ';', 'bonus', '.']\n",
      "\n",
      "\n",
      "taken \t 26 \t VERB \t ROOT \t [] \t ['In', ',', 'amount', 'amount', 'shall', 'be', 'into', 'in', '.', ']']\n",
      "\n",
      "\n",
      "calculated \t 44 \t VERB \t ROOT \t [] \t ['exceeds', ',', 'shall', 'be', 'were', '.']\n",
      "\n",
      "\n",
      "reduced \t 64 \t VERB \t ROOT \t [] \t ['worked', 'is', ',', 'shall', 'be', 'proportionately', '.']\n",
      "\n",
      "\n",
      "exceeds \t 9 \t VERB \t ROOT \t [] \t ['Where', 'for', ',', 'surplus', 'amount', ',', 'then', 'shall', '.']\n",
      "carried \t 60 \t VERB \t ROOT \t [] \t ['of', ',', 'be', 'forward', 'for', 'on']\n",
      "\n",
      "\n",
      "carried \t 90 \t VERB \t ROOT \t [] \t ['is', ',', 'then', ',', 'amount', ',', 'be', ',', 'shall', 'be', 'forward', 'for', '.']\n",
      "\n",
      "\n",
      "apply \t 15 \t VERB \t ROOT \t [] \t ['principle', 'shall', 'to', '.']\n",
      "\n",
      "\n",
      "taken \t 50 \t VERB \t ROOT \t [] \t ['carried', ',', 'amount', 'shall', 'first', 'be', 'into']\n",
      "\n",
      "\n",
      "Where \t 0 \t SCONJ \t ROOT \t [] \t ['establishment', '.']\n",
      "\n",
      "\n",
      "be \t 38 \t AUX \t ROOT \t [] \t ['In', ',', 'be', ',', 'bonus', 'shall', 'payable', 'calculated', 'with', '.']\n",
      "\n",
      "\n",
      "apply \t 41 \t VERB \t ROOT \t [] \t ['From', ',', 'be', 'from', ',', 'provisions', 'shall', 'in', 'apply', '.']\n",
      "\n",
      "\n",
      "be \t 24 \t AUX \t ROOT \t [] \t ['found', ',', 'then', ',', 'it', 'shall', 'lawful', 'deduct', 'and', 'entitled', 'any']\n",
      "\n",
      "\n",
      "sells \t 10 \t VERB \t ROOT \t [] \t ['If', 'in', 'establishment', 'goods', 'or', 'renders', ',', 'and', 'apply']\n",
      "\n",
      "\n",
      "make \t 66 \t VERB \t ROOT \t [] \t ['is', 'may', ',', 'application', 'specify', 'is', 'issue']\n",
      "\n",
      "\n",
      "Provided \t 0 \t VERB \t ROOT \t [] \t ['made']\n",
      "\n",
      "\n",
      "Provided \t 0 \t VERB \t ROOT \t [] \t ['further', 'entertained', '.']\n",
      "\n",
      "\n",
      "deemed \t 41 \t VERB \t ROOT \t [] \t ['arises', ',', 'then', ',', 'dispute', 'shall', 'be', 'be', ',', 'be', '.']\n",
      "\n",
      "\n",
      "14 \t 20 \t NUM \t ROOT \t [] \t [',', 'during', '(', 'of', ')', 'or', 'hereinafter']\n",
      "[ \t 48 \t X \t ROOT \t [] \t ['in']\n",
      "referred \t 58 \t VERB \t ROOT \t [] \t ['[', 'sections', 'to', 'referred', ',', 'audited', 'produced', 'presume']\n",
      "\n",
      "\n",
      "comply \t 119 \t VERB \t ROOT \t [] \t ['furnish', ',', 'shall', 'with', '.']\n",
      "\n",
      "\n",
      "specified \t 6 \t VERB \t ROOT \t [] \t ['Where', 'dispute', 'in', 'between', ',', 'being', ',', 'and', 'referred']\n",
      "\n",
      "\n",
      "enable \t 10 \t VERB \t ROOT \t [] \t ['Nothing', 'shall', 'union', 'obtain', ')']\n",
      "\n",
      "\n",
      "specified \t 6 \t VERB \t ROOT \t [] \t ['Where', 'dispute', 'in', 'between', ',', 'being', ',', 'and', 'referred']\n",
      "\n",
      "\n",
      "direct \t 53 \t VERB \t ROOT \t [] \t ['finds', ',', 'then', ',', 'it', 'may', ',', 'by', 'order', 'employer', 'get', 'comply']\n",
      "\n",
      "\n",
      "get \t 30 \t VERB \t ROOT \t [] \t ['fails', 'authority', 'may', ',', 'without', ',', 'accounts', '.']\n",
      "\n",
      "\n",
      "determined \t 28 \t VERB \t ROOT \t [] \t ['expenses', 'shall', 'be', 'by', 'and', 'be']\n",
      "\n",
      "\n",
      "prepare \t 3 \t VERB \t ROOT \t [] \t ['employer', 'shall', 'and', 'maintain', 'prescribed']\n",
      "\n",
      "\n",
      "appoint \t 12 \t VERB \t ROOT \t [] \t ['Government', 'may', ',', 'by', ',', 'person', 'think', '.']\n",
      "\n",
      "\n",
      "deemed \t 4 \t VERB \t ROOT \t [] \t ['Inspector', 'shall', 'be', 'be']\n",
      "\n",
      "\n",
      "bound \t 31 \t VERB \t ROOT \t [] \t ['person', 'shall', 'be', 'legally', 'do', '.']\n",
      "\n",
      "\n",
      "enable \t 6 \t VERB \t ROOT \t [] \t ['Nothing', 'shall', 'Inspector', 'require', ',', 'or', 'give', ')']\n",
      "\n",
      "\n",
      "deemed \t 54 \t VERB \t ROOT \t [] \t ['is', ',', 'person', ',', 'company', 'shall', 'be', 'be']\n",
      "\n",
      "\n",
      "diligence \t 36 \t NOUN \t ROOT \t [] \t ['Provided', 'due', 'prevent']\n",
      "\n",
      "\n",
      "Notwithstanding \t 0 \t ADP \t ROOT \t [] \t ['anything']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,row in df.iterrows():\n",
    "  sentence = row.values[0]\n",
    "  doc = nlp(sentence)\n",
    "  for token in doc:\n",
    "    ancestors = [t.text for t in token.ancestors]\n",
    "    children = [t.text for t in token.children]\n",
    "    if(token.dep_ == \"ROOT\"):\n",
    "      print(token.text, \"\\t\", token.i, \"\\t\", \n",
    "          token.pos_, \"\\t\", token.dep_, \"\\t\", \n",
    "          ancestors, \"\\t\", children)\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAmSytABHK7z",
    "outputId": "326295be-74c2-47be-8427-af63f19c118f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protection \t 0 \t NOUN \t ROOT \t [] \t ['to', '.', '-']\n",
      "lie \t 19 \t VERB \t ROOT \t [] \t ['suit', 'shall', 'against', 'for', '.']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDehp-0WHIv5",
    "outputId": "326295be-74c2-47be-8427-af63f19c118f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protection \t 0 \t NOUN \t ROOT \t [] \t ['to', '.', '-']\n",
      "lie \t 19 \t VERB \t ROOT \t [] \t ['suit', 'shall', 'against', 'for', '.']\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    ancestors = [t.text for t in token.ancestors]\n",
    "    children = [t.text for t in token.children]\n",
    "    if(token.dep_ == \"ROOT\"):\n",
    "      print(token.text, \"\\t\", token.i, \"\\t\", \n",
    "          token.pos_, \"\\t\", token.dep_, \"\\t\", \n",
    "          ancestors, \"\\t\", children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_IgA4H-E6pi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWW1VnZ9E6l8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOU47IrpOboI"
   },
   "outputs": [],
   "source": [
    "sentence = \"Protection to persons acting under the Act. - No suit, prosecution or other legal proceeding whatsoever shall lie against any person for anything which is in good faith done or intended to be done in due discharge of his duties under this Act.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkmrblIEOdv2"
   },
   "outputs": [],
   "source": [
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9TRnSGWOfCK",
    "outputId": "326295be-74c2-47be-8427-af63f19c118f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protection \t 0 \t NOUN \t ROOT \t [] \t ['to', '.', '-']\n",
      "lie \t 19 \t VERB \t ROOT \t [] \t ['suit', 'shall', 'against', 'for', '.']\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    ancestors = [t.text for t in token.ancestors]\n",
    "    children = [t.text for t in token.children]\n",
    "    if(token.dep_ == \"ROOT\"):\n",
    "      print(token.text, \"\\t\", token.i, \"\\t\", \n",
    "          token.pos_, \"\\t\", token.dep_, \"\\t\", \n",
    "          ancestors, \"\\t\", children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kgL9oxPOg4u"
   },
   "outputs": [],
   "source": [
    "def find_root_of_sentence(doc):\n",
    "    root_token = None\n",
    "    for token in doc:\n",
    "        if (token.dep_ == \"ROOT\"):\n",
    "            root_token = token\n",
    "    return root_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQ3hUGKCOjeT"
   },
   "outputs": [],
   "source": [
    "root_token = find_root_of_sentence(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JG103jHJOksw"
   },
   "outputs": [],
   "source": [
    "def find_other_verbs(doc, root_token):\n",
    "    other_verbs = []\n",
    "    for token in doc:\n",
    "        ancestors = list(token.ancestors)\n",
    "        if (token.pos_ == \"VERB\" and len(ancestors) == 1\\\n",
    "            and ancestors[0] == root_token):\n",
    "            other_verbs.append(token)\n",
    "    return other_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1m7wbVAEOmDB"
   },
   "outputs": [],
   "source": [
    "other_verbs = find_other_verbs(doc, root_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OEzfucUUPS4N"
   },
   "outputs": [],
   "source": [
    "def get_clause_token_span_for_verb(verb, doc, all_verbs):\n",
    "    first_token_index = len(doc)\n",
    "    last_token_index = 0\n",
    "    this_verb_children = list(verb.children)\n",
    "    for child in this_verb_children:\n",
    "        if (child not in all_verbs):\n",
    "            if (child.i < first_token_index):\n",
    "                first_token_index = child.i\n",
    "            if (child.i > last_token_index):\n",
    "                last_token_index = child.i\n",
    "    return(first_token_index, last_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Qdo3GjQPS0o"
   },
   "outputs": [],
   "source": [
    "token_spans = []   \n",
    "all_verbs = [root_token] + other_verbs\n",
    "for other_verb in all_verbs:\n",
    "    (first_token_index, last_token_index) = \\\n",
    "     get_clause_token_span_for_verb(other_verb, \n",
    "                                    doc, all_verbs)\n",
    "    token_spans.append((first_token_index, \n",
    "                        last_token_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckEOXFcdPSxb"
   },
   "outputs": [],
   "source": [
    "sentence_clauses = []\n",
    "for token_span in token_spans:\n",
    "    start = token_span[0]\n",
    "    end = token_span[1]\n",
    "    if (start < end):\n",
    "        clause = doc[start:end]\n",
    "        sentence_clauses.append(clause)\n",
    "sentence_clauses = sorted(sentence_clauses, \n",
    "                          key=lambda tup: tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kN27J4XUPSkG",
    "outputId": "c734386d-702f-407b-b0f5-3e82400811c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['suit, prosecution or other legal proceeding whatsoever shall lie against any person for anything which is in good faith done or intended to be done in due discharge of his duties under this Act']\n"
     ]
    }
   ],
   "source": [
    "clauses_text = [clause.text for clause in sentence_clauses]\n",
    "print(clauses_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzOBThjOptM-"
   },
   "source": [
    "VAISHNAVI'S AIM-ATTRIBUTE-DEONTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOFxFRNzcBym",
    "outputId": "b8c8f059-883d-401b-e126-b4982cff1969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suit NOUN nsubj\n",
      "attribute: suit\n",
      "aim: lie\n",
      "deontic: shall\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('merge_noun_chunks')\n",
    "# text = \"Every rule made under this Act shall be laid, as soon as maybe after it is made, before each House of Parliament, while it is in session, for a total period of thirty days which may be comprised in one Session or in two or more successive sessions, and if, before the expiry of the session immediately following the session or the successive sessions aforesaid. both Houses agree in making any modification in the rule or both Houses agree that the rule should not be made, the rule shall thereafter have effect only in such modified form or be of no effect, as the case may be; so, however, that any such modification or annulment shall be without prejudice to the validity of anything previously done under that rule.\"\n",
    "# doc = nlp(text)\n",
    "i = 0\n",
    "noun_found = False\n",
    "attribute = \"\"\n",
    "deontic = \"\"\n",
    "aim = \"\"\n",
    "for text in clauses_text:\n",
    "  doc = nlp(text)\n",
    "  for entity in doc:\n",
    "      print(entity, entity.pos_, entity.dep_)\n",
    "      if (entity.pos_ == \"PROPN\" or entity.pos_ == \"NOUN\"):\n",
    "          attribute = str(entity)\n",
    "          aim = str(entity.head.text)\n",
    "          aim_found = True\n",
    "          break\n",
    "\n",
    "  for entity in doc:\n",
    "    if (entity.pos_ == \"AUX\") and (aim == entity.head.text):\n",
    "      deontic = str(entity)\n",
    "      # print(deontic + entity.head.text)\n",
    "\n",
    "# print(doc.vocab)\n",
    "\n",
    "# for chunk in doc.noun_chunks:\n",
    "#     if str(chunk.text) == attribute:\n",
    "#         aim = str(chunk.root.head.text)\n",
    "\n",
    "print(\"attribute: \" + attribute)\n",
    "print(\"aim: \" + aim)\n",
    "print(\"deontic: \" + deontic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpUAGS4UVtsU"
   },
   "source": [
    "# **REPLICATING ONLINE SPACY**\n",
    "\n",
    "DHRUV'S AIM-ATTRIBUTE-DEONTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDtrr1vpR7En"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = \"\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "\n",
    "def merge_phrases(doc):\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for np in list(doc.noun_chunks):\n",
    "            attrs = {\n",
    "                \"tag\": np.root.tag_,\n",
    "                \"lemma\": np.root.lemma_,\n",
    "                \"ent_type\": np.root.ent_type_,\n",
    "            }\n",
    "            retokenizer.merge(np, attrs=attrs)\n",
    "    return doc\n",
    "\n",
    "def merge_punct(doc):\n",
    "    spans = []\n",
    "    for word in doc[:-1]:\n",
    "        if word.is_punct or not word.nbor(1).is_punct:\n",
    "            continue\n",
    "        start = word.i\n",
    "        end = word.i + 1\n",
    "        while end < len(doc) and doc[end].is_punct:\n",
    "            end += 1\n",
    "        span = doc[start:end]\n",
    "        spans.append((span, word.tag_, word.lemma_, word.ent_type_))\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for span, tag, lemma, ent_type in spans:\n",
    "            attrs = {\"tag\": tag, \"lemma\": lemma, \"ent_type\": ent_type}\n",
    "            retokenizer.merge(span, attrs=attrs)\n",
    "    return doc\n",
    "\n",
    "# Merge noun phrases into one token.\n",
    "doc = merge_phrases(doc)\n",
    "# Attach punctuation to tokens\n",
    "doc = merge_punct(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INayE3oaaKfT"
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "  ancestors = [t.text for t in token.ancestors]\n",
    "  ancestors_token = [t for t in token.ancestors]\n",
    "  children = [t.text for t in token.children]\n",
    "  children_token = [t for t in token.children]\n",
    "  left = [t.text for t in token.lefts]\n",
    "  right = [t.text for t in token.rights]\n",
    "  print(token.text, token.pos_, token.dep_,ancestors,children,left,right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPG8wIXeZw4F",
    "outputId": "9c827b0f-e918-48fa-cea5-997cfc53fd29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ners = [(e,type(e)) for e in doc.ents]\n",
    "ners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "octN1zmMZTwO",
    "outputId": "5ab589d5-dce4-4350-df1e-07b68757dfa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f9a5f665280>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f9a5f6656a0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f9a5fcbdd60>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f9a5f72c100>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f9a5f7d7700>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f9a5f969eb0>)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline\n",
    "# Tagger identifies verb, noun etc\n",
    "# Parser identifies relationships b/w different tokens\n",
    "# ner labels named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-rTTsUOUBgy"
   },
   "outputs": [],
   "source": [
    "attribute = []\n",
    "attribute_token = []\n",
    "aim = []\n",
    "aim_token = []\n",
    "deontic = []\n",
    "deontic_token = []\n",
    "aim_2 = []\n",
    "aim_2_token = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taKwIct-ownU"
   },
   "source": [
    "For Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcLlfG2ume-i"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for entity in doc:\n",
    "  print(entity)\n",
    "  if ((entity.pos_ == \"PROPN\" or entity.pos_ == \"NOUN\" or \"PRON\") and (entity.dep_ == \"nsubjpass\" or entity.dep_ == \"nsubj\")):\n",
    "    attribute.append(entity.text)\n",
    "    attribute_token.append(entity)\n",
    "    for attr in entity.children:\n",
    "      if attr.dep_ == 'conj' and (attr.pos_ == \"PROPN\" or attr.pos_ == \"NOUN\"):\n",
    "        attribute.append(attr.text)\n",
    "        attribute_token.append(attr)\n",
    "    \n",
    "  if(len(attribute)>0):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MS7Z8Zome69",
    "outputId": "b6cddbfb-73d8-486f-f741-2ab338afce30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlXg3r-DozOy"
   },
   "source": [
    "For Deontic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66m6SiHrme35"
   },
   "outputs": [],
   "source": [
    "for entity in doc:\n",
    "  print(entity)\n",
    "  if ((entity.pos_ == \"AUX\") and (entity.dep_ == \"aux\" or entity.dep_ == \"auxpass\")):\n",
    "    deontic.append(entity.text)\n",
    "    deontic_token.append(entity)\n",
    "    break\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDf_I2Nxyfxt",
    "outputId": "8de5a4dc-5f78-4140-e308-3a6b8ed8d10c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(deontic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvS4kyk2yBMA"
   },
   "source": [
    "For Aim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUgaBEqtyASy"
   },
   "outputs": [],
   "source": [
    "for entity in doc:\n",
    "  if (entity.pos_ =='NOUN' or entity.pos_ =='VERB'):\n",
    "    for child in entity.children:\n",
    "      if (child in attribute_token) and (child.dep_ == 'nsubj' or child.dep_ =='nsubjpass'):\n",
    "        aim.append(entity.text)\n",
    "        aim_token.append(entity)\n",
    "\n",
    "        for attr in entity.children:\n",
    "          if attr.dep_ == 'conj' and (attr.pos_ == \"NOUN\" or attr.pos_ == \"VERB\"):\n",
    "            aim.append(attr.text)\n",
    "            aim_token.append(attr)\n",
    "  \n",
    "  if(len(aim)>0):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSYZ72s_gcI0",
    "outputId": "b68de588-2d6e-4d56-b581-220ebf7a9675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(aim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUG8Q5J3dPWc"
   },
   "source": [
    "Aim Updated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBPkwInWdOW4"
   },
   "outputs": [],
   "source": [
    "for entity in doc:\n",
    "  if (entity.pos_ =='VERB'):\n",
    "    for child in entity.children:\n",
    "      if (child in deontic_token) and (child.dep_ == 'aux'):\n",
    "        aim_2.append(entity.text)\n",
    "        aim_2_token.append(entity)\n",
    "\n",
    "        for attr in entity.children:\n",
    "          if attr.dep_ == 'conj' and (attr.pos_ == \"NOUN\" or attr.pos_ == \"VERB\"):\n",
    "            aim.append(attr.text)\n",
    "            aim_token.append(attr)\n",
    "  \n",
    "  if(len(aim_2)>0):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Js2IT1C1dbt",
    "outputId": "3f93ac3d-91a4-48d6-f8e4-86dc790f644f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(aim_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhYdd1Kl3qKd"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42mfxGE4JwFH"
   },
   "source": [
    "##Testing on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXdTrCU8J1Sb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "\n",
    "# import gspread\n",
    "# from google.auth import default\n",
    "# creds, _ = default()\n",
    "\n",
    "# gc = gspread.authorize(creds)\n",
    "# sheet = gc.open_by_url('SHEET LINK HERE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAOqsN5XJ69W"
   },
   "outputs": [],
   "source": [
    "# worksheet = sheet.worksheet('SUBSHEET NAME HERE')\n",
    "# rows = worksheet.get_all_values()\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame.from_records(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MI5T_py3J9KW"
   },
   "outputs": [],
   "source": [
    "# df\n",
    "# df = df.drop(index=0)\n",
    "# df.columns = [\"Sentence\",\"Attribute\",\"Aim\",\"Deontic\",\"Context\",\"B\",\"O\",\"Attribute_test\",\"Aim_test\",\"Deontic_test\"]\n",
    "# attr1 = []\n",
    "# aim1 = []\n",
    "# deo1 = []\n",
    "\n",
    "# for sentence in df[\"Sentence\"]:\n",
    "#   doc = nlp(sentence)\n",
    "#   # Merge noun phrases into one token.\n",
    "#   doc = merge_phrases(doc)\n",
    "#   # Attach punctuation to tokens\n",
    "#   doc = merge_punct(doc)\n",
    "#   for token in doc:\n",
    "#     ancestors = [t.text for t in token.ancestors]\n",
    "#     ancestors_token = [t for t in token.ancestors]\n",
    "#     children = [t.text for t in token.children]\n",
    "#     children_token = [t for t in token.children]\n",
    "#     left = [t.text for t in token.lefts]\n",
    "#     right = [t.text for t in token.rights]\n",
    "#   ners = [(e,type(e)) for e in doc.ents]\n",
    "#   nlp.pipeline\n",
    "#   attribute = []\n",
    "#   attribute_token = []\n",
    "#   aim = []\n",
    "#   aim_token = []\n",
    "#   deontic = []\n",
    "#   deontic_token = []\n",
    "#   #attributes\n",
    "#   i = 0\n",
    "#   for entity in doc:\n",
    "#     if ((entity.pos_ == \"PROPN\" or entity.pos_ == \"NOUN\" or \"PRON\") and (entity.dep_ == \"nsubjpass\" or entity.dep_ == \"nsubj\")):\n",
    "#       attribute.append(entity.text)\n",
    "#       attribute_token.append(entity)\n",
    "#       for attr in entity.children:\n",
    "#         if attr.dep_ == 'conj' and (attr.pos_ == \"PROPN\" or attr.pos_ == \"NOUN\"):\n",
    "#           attribute.append(attr.text)\n",
    "#           attribute_token.append(attr)\n",
    "      \n",
    "#     if(len(attribute)>0):\n",
    "#       break\n",
    "  \n",
    "#   for entity in doc:\n",
    "#     print(entity)\n",
    "#     if ((entity.pos_ == \"AUX\") and (entity.dep_ == \"aux\" or entity.dep_ == \"auxpass\")):\n",
    "#       deontic.append(entity.text)\n",
    "#       deontic_token.append(entity)\n",
    "#       break\n",
    "  \n",
    "#   for entity in doc:\n",
    "#     if (entity.pos_ =='NOUN' or entity.pos_ =='VERB'):\n",
    "#       for child in entity.children:\n",
    "#         if (child in attribute_token) and (child.dep_ == 'nsubj' or child.dep_ =='nsubjpass'):\n",
    "#           aim.append(entity.text)\n",
    "#           aim_token.append(entity)\n",
    "\n",
    "#           for attr in entity.children:\n",
    "#             if attr.dep_ == 'conj' and (attr.pos_ == \"NOUN\" or attr.pos_ == \"VERB\"):\n",
    "#               aim.append(attr.text)\n",
    "#               aim_token.append(attr)\n",
    "    \n",
    "#     if(len(aim)>0):\n",
    "#       break\n",
    "#   attr1.append(attribute)\n",
    "#   aim1.append(aim)\n",
    "#   deo1.append(deontic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOqsfz29KDau"
   },
   "outputs": [],
   "source": [
    "# df[\"Attribute_test\"] = attr1\n",
    "# df[\"Aim_test\"] = aim1\n",
    "# df[\"Deontic_test\"] = deo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUy92b1kKFHm"
   },
   "outputs": [],
   "source": [
    "# sh = gc.create('A new spreadsheet')\n",
    "\n",
    "# # Open our new sheet and add some data.\n",
    "# # worksheet = gc.open('A new spreadsheet').sheet1\n",
    "# sheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/1iS9MeDIB4JVgpig5s4x3PArDaO81CGEpjokSQNDJhyE/edit#gid=0')\n",
    "# worksheet = sheet.worksheet('Sheet2')\n",
    "\n",
    "\n",
    "# df.to_csv('test_results.csv', index = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
